import os
import time
import logging
import threading
import pygame
import wave
import numpy as np
import sounddevice as sd
from datetime import datetime
from scipy.io import wavfile

class PhoneMode:
    def __init__(self, socketio, chatbot, transcribe_func, tts_func, save_message_func, 
                should_trigger_vision_func=None, analyze_frame_func=None):
        self.socketio = socketio
        self.chatbot = chatbot
        self.transcribe_func = transcribe_func
        self.tts_func = tts_func
        self.save_message_func = save_message_func
        self.should_trigger_vision = should_trigger_vision_func
        self.analyze_frame = analyze_frame_func
        self.active = False
        self.is_recording = False
        self.recording_thread = None
        self.audio_file = "uploads/phone_mode_audio.wav"
        self.start_beep = "static/start_beep.wav"
        self.stop_beep = "static/stop_beep.wav"
    
    def start(self):
        """å•Ÿå‹•é›»è©±æ¨¡å¼"""
        if self.active:
            return False
            
        self.active = True
        return self._start_recording_cycle()
    
    def stop(self):
        """åœæ­¢é›»è©±æ¨¡å¼"""
        self.active = False
        self._ensure_beep_files()
        self._play_beep(self.stop_beep)  # æ’­æ”¾çµæŸæç¤ºéŸ³
        return True
    
    def _ensure_beep_files(self):
        """ç¢ºä¿æç¤ºéŸ³æ–‡ä»¶å­˜åœ¨"""
        for beep_file in [self.start_beep, self.stop_beep]:
            if not os.path.exists(beep_file):
                logging.warning(f"æç¤ºéŸ³æ–‡ä»¶ä¸å­˜åœ¨: {beep_file}")
                return False
        return True
        
    def _play_beep(self, beep_file):
        """æ’­æ”¾æç¤ºéŸ³"""
        try:
            if not os.path.exists(beep_file):
                logging.warning(f"æç¤ºéŸ³æ–‡ä»¶ä¸å­˜åœ¨: {beep_file}")
                return
                
            # é€šçŸ¥å‰ç«¯æ’­æ”¾éŸ³é »
            self.socketio.emit('play_audio', {'audio_file': f'/{beep_file}'})
            
            # æœ¬åœ°ä¹Ÿæ’­æ”¾æç¤ºéŸ³
            pygame.mixer.Sound(beep_file).play()
            
            logging.info(f"æ’­æ”¾æç¤ºéŸ³: {beep_file}")
        except Exception as e:
            logging.error(f"æ’­æ”¾æç¤ºéŸ³å¤±æ•—: {e}")
    
    def _start_recording_cycle(self):
        """é–‹å§‹éŒ„éŸ³å¾ªç’°"""
        if not self._ensure_beep_files():
            return False
            
        # æ’­æ”¾é–‹å§‹æç¤ºéŸ³
        self._play_beep(self.start_beep)
        
        # å•Ÿå‹•éŒ„éŸ³ç·šç¨‹
        self.recording_thread = threading.Thread(target=self._recording_worker)
        self.recording_thread.daemon = True
        self.recording_thread.start()
        
        return True
    
    def _recording_worker(self):
        """éŒ„éŸ³å·¥ä½œç·šç¨‹"""
        import sounddevice as sd
        import numpy as np
        import wave
        import webrtcvad
        from scipy.io import wavfile
        
        # å‰µå»ºä¿å­˜ç›®éŒ„
        os.makedirs("uploads", exist_ok=True)
        
        # è¨­ç½®éŒ„éŸ³åƒæ•¸
        duration = 60  # æœ€é•·éŒ„éŸ³æ™‚é–“ï¼ˆç§’ï¼‰
        fs = 16000     # æ¡æ¨£ç‡
        channels = 1   # å–®è²é“
        
        # åˆå§‹åŒ–VAD
        vad = webrtcvad.Vad()
        vad.set_mode(3)  # è¨­ç½®ç‚ºæœ€æ•æ„Ÿæ¨¡å¼
        
        chunk_duration = 0.02  # 20ms chunks for VAD
        chunk_samples = int(fs * chunk_duration)
        
        # é–‹å§‹éŒ„éŸ³
        self.is_recording = True
        
        logging.info("é–‹å§‹é›»è©±æ¨¡å¼éŒ„éŸ³...")
        
        frames = []
        silent_chunks = 0
        speech_detected = False
        max_silent_chunks = int(5 / chunk_duration)   # 5ç§’éœéŸ³å¾ŒçµæŸ (å·²æª¢æ¸¬åˆ°èªéŸ³)
        max_wait_chunks = int(10 / chunk_duration)    # 10ç§’ç­‰å¾… (æœªæª¢æ¸¬åˆ°èªéŸ³)
        total_chunks = 0
        
        try:
            # é–‹å§‹éŒ„éŸ³
            audio_data = sd.rec(int(duration * fs), samplerate=fs, channels=channels, dtype=np.int16)
            
            # æ¯éš”ä¸€å°æ®µæ™‚é–“æª¢æŸ¥æ˜¯å¦æœ‰èªéŸ³
            for i in range(int(duration / chunk_duration)):
                if not self.active or total_chunks >= int(duration / chunk_duration):
                    break
                    
                time.sleep(chunk_duration)
                total_chunks += 1
                
                # ç²å–ç•¶å‰éŒ„éŸ³çš„é€™ä¸€å°æ®µ
                if i * chunk_samples < len(audio_data):
                    current_chunk = audio_data[i*chunk_samples:min((i+1)*chunk_samples, len(audio_data))]
                    
                    # è½‰æ›ç‚ºbytesç”¨æ–¼VAD
                    chunk_bytes = current_chunk.tobytes()
                    
                    # æª¢æ¸¬æ˜¯å¦æœ‰èªéŸ³
                    try:
                        is_speech = vad.is_speech(chunk_bytes, fs)
                    except Exception:
                        is_speech = False
                    
                    if is_speech:
                        silent_chunks = 0
                        speech_detected = True
                        frames.append(current_chunk.copy())
                    else:
                        silent_chunks += 1
                        if speech_detected:  # å¦‚æœä¹‹å‰æª¢æ¸¬åˆ°éèªéŸ³ï¼Œä¹Ÿä¿å­˜éœéŸ³ç‰‡æ®µ
                            frames.append(current_chunk.copy())
                    
                    # å¦‚æœæª¢æ¸¬åˆ°èªéŸ³å¾Œæœ‰è¶³å¤ é•·çš„éœéŸ³ï¼ŒçµæŸéŒ„éŸ³
                    if speech_detected and silent_chunks >= max_silent_chunks:
                        logging.info("æª¢æ¸¬åˆ°5ç§’éœéŸ³ï¼ŒçµæŸéŒ„éŸ³")
                        break
                    
                    # å¦‚æœç­‰å¾…å¤ªä¹…æ²’æœ‰æª¢æ¸¬åˆ°èªéŸ³ï¼Œä¹ŸçµæŸéŒ„éŸ³
                    if not speech_detected and total_chunks >= max_wait_chunks:
                        logging.info("10ç§’å…§æœªæª¢æ¸¬åˆ°èªéŸ³ï¼ŒçµæŸéŒ„éŸ³")
                        break
            
            # åœæ­¢éŒ„éŸ³
            sd.stop()
            
            # æ’­æ”¾çµæŸæç¤ºéŸ³
            self._play_beep(self.stop_beep)
            
            # å¦‚æœæ²’æœ‰æª¢æ¸¬åˆ°èªéŸ³æˆ–å¹€æ•¸å¤ªå°‘ï¼Œè¦–ç‚ºç„¡æ•ˆéŒ„éŸ³
            if not speech_detected or len(frames) < 10:
                logging.info("æœªæª¢æ¸¬åˆ°æœ‰æ•ˆèªéŸ³ï¼Œé‡æ–°é–‹å§‹éŒ„éŸ³å¾ªç’°")
                self.is_recording = False
                
                # å¦‚æœé›»è©±æ¨¡å¼ä»ç„¶æ´»èºï¼Œé–‹å§‹æ–°çš„éŒ„éŸ³å¾ªç’°
                if self.active:
                    time.sleep(1)  # ç­‰å¾…ä¸€ç§’
                    self._start_recording_cycle()
                return
            
            # ä¿å­˜éŒ„éŸ³
            if frames:
                combined_frames = np.vstack(frames) if len(frames) > 1 else frames[0]
                wavfile.write(self.audio_file, fs, combined_frames)
                logging.info(f"å·²ä¿å­˜éŒ„éŸ³: {self.audio_file}")
                
                # è™•ç†éŒ„éŸ³
                self._process_recording()
            
        except Exception as e:
            logging.error(f"éŒ„éŸ³éç¨‹ä¸­å‡ºéŒ¯: {e}")
            import traceback
            traceback.print_exc()
        finally:
            self.is_recording = False

    def _process_recording(self):
        """è™•ç†éŒ„éŸ³æ–‡ä»¶"""
        try:
            # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(self.audio_file):
                logging.error(f"éŒ„éŸ³æ–‡ä»¶ä¸å­˜åœ¨: {self.audio_file}")
                return
                    
            # é€šçŸ¥å‰ç«¯æª¢æ¸¬åˆ°èªéŸ³
            self.socketio.emit('phone_mode_speech_detected')
                
            # è½‰éŒ„èªéŸ³
            transcribed_text = self.transcribe_func(self.audio_file)
                
            if not transcribed_text:
                logging.warning("ç„¡æ³•è­˜åˆ¥èªéŸ³å…§å®¹")
                # å¦‚æœé›»è©±æ¨¡å¼ä»ç„¶æ´»èºï¼Œé–‹å§‹æ–°çš„éŒ„éŸ³å¾ªç’°
                if self.active:
                    self._start_recording_cycle()
                return
                        
            logging.info(f"è­˜åˆ¥åˆ°èªéŸ³: {transcribed_text}")
            
            # ä¿å­˜ç”¨æˆ¶æ¶ˆæ¯
            user_message = {
                "type": "sent",
                "text": f"ğŸ“ {transcribed_text}",
                "timestamp": datetime.now().isoformat(),
                "audioSrc": None
            }
            self.save_message_func(user_message)
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦è§¸ç™¼ AI Vision åˆ†æ
            if self.should_trigger_vision and self.should_trigger_vision(transcribed_text):
                logging.info("è§¸ç™¼ AI Vision åˆ†æ")
                if self.analyze_frame:
                    # å‚³é socketio å¯¦ä¾‹
                    self.analyze_frame(self.socketio)
                
                # ç­‰å¾…ä¸€æ®µæ™‚é–“å¾Œå†é–‹å§‹æ–°çš„éŒ„éŸ³å¾ªç’°
                time.sleep(5)  # ç­‰å¾… 5 ç§’
                if self.active:
                    self._start_recording_cycle()
                return
            
            # ç²å–AIå›æ‡‰
            ai_response = self.chatbot.get_response(transcribed_text)
            
            # ç”ŸæˆèªéŸ³
            tts_file = self.tts_func(ai_response)
            
            # ä¿å­˜AIå›æ‡‰
            ai_message = {
                "type": "received",
                "text": f"ğŸ“ {ai_response}",
                "timestamp": datetime.now().isoformat(),
                "audioSrc": tts_file
            }
            self.save_message_func(ai_message)
            
            # ç™¼é€å›æ‡‰åˆ°å‰ç«¯
            self.socketio.emit('phone_mode_response', {
                "text": ai_response,
                "audio_file": tts_file
            })
            
            # è¨ˆç®—TTSæ–‡ä»¶é•·åº¦ä¸¦å¢åŠ é¡å¤–ç­‰å¾…æ™‚é–“
            extra_wait_time = 5  # æ’­æ”¾å®ŒTTSå¾Œçš„é¡å¤–ç­‰å¾…æ™‚é–“ï¼ˆç§’ï¼‰
            
            if tts_file:
                # ç§»é™¤å¼€å¤´çš„æ–œæ ä»¥é¿å…è·¯å¾„é‡å¤
                file_path = tts_file.lstrip('/')
                
                if os.path.exists(file_path):
                    # ä½¿ç”¨waveæ¨¡å—è¯»å–éŸ³é¢‘æ–‡ä»¶æ—¶é•¿
                    try:
                        with wave.open(file_path, 'rb') as wf:
                            # è®¡ç®—éŸ³é¢‘é•¿åº¦ï¼ˆç§’ï¼‰
                            tts_duration = wf.getnframes() / wf.getframerate()
                            total_wait = tts_duration + extra_wait_time
                            logging.info(f"TTSæ™‚é•·: {tts_duration:.2f}ç§’ï¼Œç¸½ç­‰å¾…æ™‚é–“: {total_wait:.2f}ç§’")
                            time.sleep(total_wait)
                    except Exception as e:
                        # å¦‚æœè¯»å–æ–‡ä»¶æ—¶å‡ºé”™ï¼Œè®°å½•é”™è¯¯å¹¶ä½¿ç”¨é¢„è®¾ç­‰å¾…æ—¶é—´
                        logging.error(f"è®€å–TTSæ–‡ä»¶æ™‚å‡ºéŒ¯: {e}")
                        default_wait = 10
                        logging.info(f"ä½¿ç”¨é è¨­ç­‰å¾…æ™‚é–“: {default_wait}ç§’")
                        time.sleep(default_wait)
                else:
                    # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè®°å½•é”™è¯¯å¹¶ä½¿ç”¨é¢„è®¾ç­‰å¾…æ—¶é—´
                    logging.warning(f"TTSæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                    default_wait = 10
                    logging.info(f"ä½¿ç”¨é è¨­ç­‰å¾…æ™‚é–“: {default_wait}ç§’")
                    time.sleep(default_wait)
            else:
                # å¦‚æœæ²¡æœ‰TTSæ–‡ä»¶è·¯å¾„ï¼Œä½¿ç”¨é¢„è®¾ç­‰å¾…æ—¶é—´
                default_wait = 10
                logging.info(f"ç„¡TTSæ–‡ä»¶è·¯å¾‘ï¼Œä½¿ç”¨é è¨­ç­‰å¾…æ™‚é–“: {default_wait}ç§’")
                time.sleep(default_wait)
            
            # å¦‚æœé›»è©±æ¨¡å¼ä»ç„¶æ´»èºï¼Œé–‹å§‹æ–°çš„éŒ„éŸ³å¾ªç’°
            if self.active:
                self._start_recording_cycle()
                
        except Exception as e:
            logging.error(f"è™•ç†éŒ„éŸ³æ™‚å‡ºéŒ¯: {e}")
            import traceback
            traceback.print_exc()
            
            # å¦‚æœé›»è©±æ¨¡å¼ä»ç„¶æ´»èºï¼Œå˜—è©¦é–‹å§‹æ–°çš„éŒ„éŸ³å¾ªç’°
            if self.active:
                time.sleep(2)  # ç­‰å¾…2ç§’
                self._start_recording_cycle()