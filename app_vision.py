import logging
import base64
import traceback
from datetime import datetime
from app_audio import generate_tts
from azure.ai.vision.imageanalysis import ImageAnalysisClient
from azure.ai.vision.imageanalysis.models import VisualFeatures
from config import AZURE_VISION_ENDPOINT, AZURE_VISION_KEY
from azure.core.credentials import AzureKeyCredential

# å…¨å±€å˜é‡ï¼Œä¼šåœ¨app_main.pyä¸­è®¾ç½®
vision_client = None
chatbot = None
save_chat_message = None

def init_vision_module(vision_client_instance, chatbot_instance, save_chat_message_func):
    """åˆå§‹åŒ–è§†è§‰æ¨¡å—"""
    global vision_client, chatbot, save_chat_message
    vision_client = vision_client_instance
    chatbot = chatbot_instance
    save_chat_message = save_chat_message_func
    
    logging.info("Visualæ¨¡å—åˆå§‹åŒ–å®Œæˆ")

def analyze_image_with_vision(image_path):
    """ä½¿ç”¨Azure Visionåˆ†æåœ–ç‰‡"""
    try:
        # è®€å–åœ–ç‰‡äºŒé€²åˆ¶æ•¸æ“š
        with open(image_path, 'rb') as image_file:
            image_data = image_file.read()
            
        # ä½¿ç”¨Azure Visionå®¢æˆ¶ç«¯åˆ†æåœ–ç‰‡
        result = vision_client.analyze(
            image_data=image_data,
            visual_features=[
                VisualFeatures.CAPTION,
                VisualFeatures.OBJECTS,
                VisualFeatures.TAGS
            ],
            gender_neutral_caption=True
        )
        
        # æå–åˆ†æçµæœ
        caption = ""
        if hasattr(result, 'caption') and result.caption:
            caption = result.caption.text
            
        objects = []
        if hasattr(result, 'objects') and result.objects:
            for obj in result.objects:
                if hasattr(obj, 'name'):
                    objects.append(obj.name)
                    
        tags = []
        if hasattr(result, 'tags') and result.tags:
            for tag in result.tags:
                if hasattr(tag, 'name'):
                    tags.append(tag.name)
                    
        # ç”Ÿæˆæ–‡æœ¬æè¿°
        analysis_text = f"ğŸ“· åœ–ç‰‡åˆ†æçµæœ:\n\n"
        
        if caption:
            analysis_text += f"é€™å¼µåœ–ç‰‡é¡¯ç¤ºçš„æ˜¯ {caption}ã€‚\n\n"
            
        if objects:
            analysis_text += f"åœ–ä¸­å¯è¦‹çš„ç‰©é«”: {', '.join(objects)}ã€‚\n\n"
            
        if tags:
            analysis_text += f"ç›¸é—œæ¨™ç±¤: {', '.join(tags)}ã€‚"
            
        return {
            'caption': caption,
            'objects': objects,
            'tags': tags,
            'text': analysis_text
        }
    except Exception as e:
        logging.error(f"åˆ†æåœ–ç‰‡æ™‚å‡ºéŒ¯: {e}")
        return {
            'caption': 'åˆ†æå¤±æ•—',
            'objects': [],
            'tags': [],
            'text': f"æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•åˆ†æé€™å¼µåœ–ç‰‡ã€‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
        }

def is_person_detected(caption, objects, tags):
    """æ£€æŸ¥æ˜¯å¦æ£€æµ‹åˆ°äººç‰©"""
    person_related_terms = ["person", "people", "human", "man", "woman", "boy", "girl", "child", "baby", "face", 
                            "äºº", "äººç‰©", "ç”·äºº", "å¥³äºº", "å°å­©", "å¬°å…’", "è‡‰", "é¢å­”"]
    
    # æ£€æŸ¥æ ‡é¢˜ã€ç‰©ä½“å’Œæ ‡ç­¾ä¸­æ˜¯å¦æœ‰äººç‰©ç›¸å…³è¯
    if any(term.lower() in caption.lower() for term in person_related_terms):
        return True
    
    for obj in objects:
        if any(term.lower() in obj.lower() for term in person_related_terms):
            return True
            
    for tag in tags:
        if any(term.lower() in tag.lower() for term in person_related_terms):
            return True
            
    return False

def analyze_current_frame(socketio_instance=None):
    """åˆ†æç•¶å‰æ”åƒé ­ç•«é¢"""
    # æ³¨æ„ï¼šä¸è¦ä½¿ç”¨globalèªå¥ï¼Œç›´æ¥å¾ä¸»æ¨¡å¡Šç²å–æœ€æ–°çš„frameæ•¸æ“š
    try:
        # å¦‚æœæ²¡æœ‰è®¾ç½®socketioå®ä¾‹ï¼Œä»ä¸»æ¨¡å—å¯¼å…¥
        if socketio_instance is None:
            from app_main import socketio
            socketio_instance = socketio
            
        # ç›´æ¥å¾ä¸»æ¨¡å¡Šç²å–ç•¶å‰æœ€æ–°çš„frame
        from app_socket_handlers import get_latest_frame
        latest_frame = get_latest_frame()
        
        if latest_frame is None or latest_frame == "":
            response = "æŠ±æ­‰ï¼Œç›®å‰æ²’æœ‰å¯ç”¨çš„æ”åƒé ­ç•«é¢ã€‚è«‹ç¢ºä¿æ”åƒé ­å·²é–‹å•Ÿã€‚"
            socketio_instance.emit('response', {"text": response, "status": "error"})
            return

        logging.info("[VISION] é–‹å§‹è™•ç†æ”åƒé ­ç•«é¢")
        logging.info(f"[VISION] æ¥æ”¶åˆ°åœ–åƒæ•¸æ“šï¼Œé•·åº¦: {len(latest_frame) if latest_frame else 0}")
        
        # å°‡ base64 åœ–ç‰‡æ•¸æ“šè½‰æ›ç‚ºäºŒé€²åˆ¶
        try:
            image_data = base64.b64decode(latest_frame)
            logging.info(f"[VISION] æˆåŠŸè§£ç¢¼åœ–ç‰‡æ•¸æ“šï¼Œå¤§å°: {len(image_data)} bytes")
        except Exception as e:
            logging.error(f"[VISION] åœ–ç‰‡è§£ç¢¼å¤±æ•—: {e}")
            response = "æŠ±æ­‰ï¼Œåœ–åƒæ•¸æ“šç„¡æ³•è§£ç¢¼ï¼Œè«‹é‡è©¦ã€‚"
            socketio_instance.emit('response', {"text": response, "status": "error"})
            return

        # åˆ†æåœ–ç‰‡
        from app_main import vision_client, chatbot, save_chat_message
        
        result = vision_client.analyze(
            image_data=image_data,
            visual_features=[
                VisualFeatures.CAPTION,
                VisualFeatures.OBJECTS,
                VisualFeatures.TAGS
            ],
            gender_neutral_caption=True
        )

        logging.info(f"[VISION] åœ–ç‰‡åˆ†æå®Œæˆï¼Œé–‹å§‹è™•ç†çµæœ")

        # æ”¶é›†åˆ†æçµæœ
        caption = ""
        confidence = 0
        if hasattr(result, 'caption') and result.caption:
            caption = result.caption.text
            confidence = result.caption.confidence

        objects = []
        if hasattr(result, 'objects') and result.objects:
            for obj in result.objects:
                if hasattr(obj, 'name'):
                    objects.append(obj.name)

        tags = []
        if hasattr(result, 'tags') and result.tags:
            for tag in result.tags:
                if hasattr(tag, 'name'):
                    tags.append(tag.name)

        # æ£€æŸ¥æ˜¯å¦è¯†åˆ«åˆ°äººç‰©ç›¸å…³çš„å†…å®¹
        detected_person = is_person_detected(caption, objects, tags)

        # æº–å‚™çµ¦ GPT çš„æç¤º
        prompt = f"""ä½œç‚ºä¸€å€‹å‹å–„çš„åŠ©æ‰‹ï¼Œè«‹ç”¨è‡ªç„¶çš„å»£æ±è©±æè¿°ä»¥ä¸‹å ´æ™¯ï¼š

å ´æ™¯æè¿°ï¼š{caption}
å¯è¦‹çš„ç‰©ä»¶ï¼š{', '.join(objects) if objects else 'ç„¡'}
å ´æ™¯ç‰¹å¾µï¼š{', '.join(tags) if tags else 'ç„¡'}

è«‹ç”¨ç°¡å–®ã€ç”Ÿæ´»åŒ–çš„æ–¹å¼æè¿°ï¼Œä¸€å®šè¦ä»¥ã€Œæˆ‘è¦‹åˆ°ã€é–‹å§‹å¥å­ã€‚"""

        response_text = ""
        tts_file = None

        try:
            # ä½¿ç”¨ chatbot ç²å– GPT å›æ‡‰
            gpt_response = chatbot.get_response(prompt)
            logging.info(f"[VISION] GPT ç”Ÿæˆå›æ‡‰: {gpt_response}")
            
            if gpt_response:
                response_text = gpt_response
            else:
                # å¦‚æœ GPT å›æ‡‰ç‚ºç©ºï¼Œä½¿ç”¨å‚™ç”¨å›æ‡‰
                backup_response = f"æˆ‘è¦‹åˆ°{caption}"
                if objects:
                    backup_response += f"ï¼Œä»²æœ‰{', '.join(objects)}"
                response_text = backup_response

        except Exception as e:
            logging.error(f"[VISION] GPT è™•ç†å¤±æ•—: {str(e)}")
            # ä½¿ç”¨åŸºæœ¬å›æ‡‰
            response_text = f"æˆ‘è¦‹åˆ°{caption}"
        
        # åªåœ¨é€™ä¸€å€‹åœ°æ–¹ç”Ÿæˆ TTS
        tts_file = generate_tts(response_text)
        
        # è¨˜éŒ„ AI å›æ‡‰åˆ°èŠå¤©æ­·å²
        ai_message = {
            "type": "received",
            "text": response_text,
            "timestamp": datetime.now().isoformat(),
            "audioSrc": tts_file
        }
        save_chat_message(ai_message)
        
        # ç™¼é€å›æ‡‰
        socketio_instance.emit('response', {
            "text": response_text,
            "audio_file": tts_file,
            "status": "success"
        })
        
        # å¦‚æœæ£€æµ‹åˆ°äººç‰©ç›¸å…³å†…å®¹ï¼Œæ‰§è¡Œä¸€æ¬¡æŒ¥æ‰‹åŠ¨ä½œ
        if detected_person:
            logging.info("[VISION] æ£€æµ‹åˆ°äººç‰©ï¼Œæ‰§è¡ŒæŒ¥æ‰‹åŠ¨ä½œ")
            # ä½¿ç”¨å•ä½æ•°åŠ¨ä½œ9ï¼ˆæŒ¥æ‰‹ï¼‰
            from app_robot_control import execute_singledigit_action
            execute_singledigit_action('9', '1')

    except Exception as e:
        logging.error(f"[VISION] åˆ†æåœ–ç‰‡æ™‚å‡ºéŒ¯: {str(e)}")
        traceback.print_exc()
        response = "æŠ±æ­‰ï¼Œåˆ†æç•«é¢æ™‚å‡ºç¾å•é¡Œï¼Œè«‹å†è©¦ä¸€æ¬¡ã€‚"
        socketio_instance.emit('response', {
            "text": response,
            "status": "error"
        })