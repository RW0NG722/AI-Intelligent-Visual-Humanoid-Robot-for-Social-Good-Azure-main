from flask import Flask, render_template, request, jsonify
from flask_socketio import SocketIO, emit
import logging
import os
import wave
import time
import whisper
import random
import importlib.util
import subprocess
import sounddevice as sd
import numpy as np
import io
import traceback
import json
from scipy.io import wavfile as wav
from datetime import datetime
import pygame
import threading
from app_audio import generate_tts, transcribe_audio
from app_socket_handlers import register_socket_handlers
from app_vision import analyze_current_frame, analyze_image_with_vision
from app_robot_control import RobotStatus, execute_singledigit_action, execute_doubledigit_action
from app_phone_mode import PhoneMode
from app_utils import initialize_chat_history, save_chat_message, is_history_outdated
from audio_manager import AudioManager
from azure.cognitiveservices.speech import SpeechConfig, SpeechSynthesizer, AudioConfig, ResultReason
from chatbot import ChatBot
from whisper_selector import SpeechToTextSelector
from config import AZURE_SPEECH_API_KEY, AZURE_SPEECH_REGION, AZURE_VISION_ENDPOINT, AZURE_VISION_KEY, WHISPER_CONFIG
from azure.ai.vision.imageanalysis import ImageAnalysisClient
from azure.ai.vision.imageanalysis.models import VisualFeatures
from azure.core.credentials import AzureKeyCredential
import base64
from pc_recorder import PCRecorder


# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler("app.log", encoding="utf-8"),
    ]
)

app = Flask(__name__, static_folder="static")
app.config['SECRET_KEY'] = 'secret!'
socketio = SocketIO(app, cors_allowed_origins="*")
latest_frame = None  # å„²å­˜æœ€æ–°å½±åƒ
last_camera_log_time = 0
camera_frame_count = 0
phone_mode_active = False
pc_recorder = PCRecorder()
pygame.mixer.init()

# èŠå¤©æ­·å²æ–‡ä»¶è·¯å¾‘
CHAT_HISTORY_FILE = "chat_history.json"
MAX_HISTORY_ENTRIES = 15

# åˆå§‹åŒ–èŠå¤©æ­·å²
chat_history = {"messages": []}

# åˆå§‹åŒ–æ¨¡å—
chatbot = ChatBot()
audio_manager = AudioManager()
stt_selector = SpeechToTextSelector(WHISPER_CONFIG)

# å…¨å±€å˜é‡
connected_robots = {}  # å­˜å‚¨å·²è¿æ¥çš„æœºå™¨äººä¿¡æ¯
current_input_mode = "pc_microphone"  # é»˜è®¤ä½¿ç”¨PCéº¦å…‹é£
current_output_mode = "pc_speaker"    # é»˜è®¤ä½¿ç”¨PCå–‡å­

# å‰µå»º Vision å®¢æˆ¶ç«¯
vision_client = ImageAnalysisClient(
    endpoint=AZURE_VISION_ENDPOINT,
    credential=AzureKeyCredential(AZURE_VISION_KEY)
)

# éŒ„éŸ³é…ç½®
SAMPLE_RATE = 16000  # 16kHz é‡‡æ¨£ç‡
CHANNELS = 1  # å–®è²é“
DURATION = 5  # éŒ„éŸ³æ™‚é–“ï¼ˆç§’ï¼‰

# æœºå™¨äººçŠ¶æ€å­—å…¸
robot_statuses = {}


def should_trigger_vision(text):
    """æª¢æŸ¥æ–‡å­—æ˜¯å¦åŒ…å«è§¸ç™¼ AI Vision çš„é—œéµè©"""
    if not text:
        return False

    vision_keywords = ['çœ‹åˆ°ä»€éº¼', 'è¦‹åˆ°ä»€éº¼', 'çœ‹åˆ°å’©é‡', 'è¦‹åˆ°å’©é‡',
                       'ä½ çœ‹è¦‹ä»€éº¼', 'ä½ çœ‹è¦‹äº†ä»€éº¼', 'çœ‹è¦‹ä»€éº¼',
                       'çœ‹åˆ°', 'çœ‹åˆ°', 'è¦‹åˆ°', 'çœ‹è¦‹', 'è¦‹åˆ°', 'ç‡åˆ°', 'ç‡è¦‹', 'ç‡åˆ°å’©', 'ç‡è¦‹å’©']

    text_lower = text.lower()
    return any(keyword in text_lower for keyword in vision_keywords)


# åˆå§‹åŒ– PhoneMode å®ä¾‹
phone_mode_manager = None


@app.route('/')
def index():
    return render_template('index.html')


@app.route('/api/test/upload-image', methods=['POST'])
def test_upload_image():
    try:
        # æª¢æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶è¢«ä¸Šå‚³
        if 'image' not in request.files:
            return jsonify({
                'success': False,
                'message': 'æœªæ‰¾åˆ°åœ–ç‰‡æ–‡ä»¶'
            }), 400

        image_file = request.files['image']

        # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰å…§å®¹
        if image_file.filename == '':
            return jsonify({
                'success': False,
                'message': 'æœªé¸æ“‡æ–‡ä»¶'
            }), 400

        # æª¢æŸ¥æ–‡ä»¶é¡å‹
        if not image_file.filename.lower().endswith(('.jpg', '.jpeg', '.png')):
            return jsonify({
                'success': False,
                'message': 'åªæ”¯æŒJPGå’ŒPNGæ ¼å¼çš„åœ–ç‰‡'
            }), 400

        # ç¢ºä¿ä¸Šå‚³ç›®éŒ„å­˜åœ¨
        upload_dir = os.path.join('static', 'uploads', 'test')
        os.makedirs(upload_dir, exist_ok=True)

        # ä¿å­˜æ–‡ä»¶
        filename = f"test_image_{int(time.time())}.jpg"
        filepath = os.path.join(upload_dir, filename)
        image_file.save(filepath)

        # ä½¿ç”¨Azure Visionåˆ†æåœ–ç‰‡
        with open(filepath, 'rb') as f:
            image_data = f.read()

        print("[DEBUG] é–‹å§‹è™•ç†æ¸¬è©¦ä¸Šå‚³åœ–ç‰‡")

        # åˆ†æåœ–ç‰‡
        result = vision_client.analyze(
            image_data=image_data,
            visual_features=[
                VisualFeatures.CAPTION,
                VisualFeatures.OBJECTS,
                VisualFeatures.TAGS
            ],
            gender_neutral_caption=True
        )

        # æå–åˆ†æçµæœ
        caption = ""
        if hasattr(result, 'caption') and result.caption:
            caption = result.caption.text

        objects = []
        if hasattr(result, 'objects') and result.objects:
            for obj in result.objects:
                if hasattr(obj, 'name'):
                    objects.append(obj.name)

        tags = []
        if hasattr(result, 'tags') and result.tags:
            for tag in result.tags:
                if hasattr(tag, 'name'):
                    tags.append(tag.name)

        # æª¢æŸ¥æ˜¯å¦è­˜åˆ¥åˆ°äººç‰©
        detected_person = False
        person_related_terms = ["person", "people", "human",
                                "man", "woman", "boy", "girl", "child", "baby", "face"]

        if any(term.lower() in caption.lower() for term in person_related_terms):
            detected_person = True

        for obj in objects:
            if any(term.lower() in obj.lower() for term in person_related_terms):
                detected_person = True
                break

        for tag in tags:
            if any(term.lower() in tag.lower() for term in person_related_terms):
                detected_person = True
                break

        # æº–å‚™å»£æ±è©±æè¿°çš„æç¤ºè©
        prompt = """ç”¨å»£æ±è©±æè¿°é€™å¼µåœ–ç‰‡ï¼Œä»¥ã€Œæˆ‘è¦‹åˆ°ã€é–‹é ­ï¼Œèªæ°£è¦è‡ªç„¶æ´»æ½‘ä¸€é»ã€‚æè¿°è¦è©³ç´°ï¼Œä½†ä¸è¦å¤ªé•·ã€‚"""

        # ä½¿ç”¨ chatbot ç²å– GPT å›æ‡‰
        print("[DEBUG] å°‡ç›´æ¥é€šé chatbot ç²å–å›æ‡‰")

        try:
            # ä½¿ç”¨ç¾æœ‰çš„ chatbot å°è±¡è€Œä¸æ˜¯å‰µå»ºæ–°çš„
            gpt_response = chatbot.get_response(
                prompt + f"\n\nåœ–ç‰‡æè¿°: {caption}\nå¯è¦‹ç‰©ä»¶: {', '.join(objects)}\næ¨™ç±¤: {', '.join(tags)}")

            print(f"[DEBUG] GPTå›æ‡‰: {gpt_response}")

            # ç¢ºä¿å›æ‡‰ä»¥ã€Œæˆ‘è¦‹åˆ°ã€é–‹é ­ (å¦‚æœä¸æ˜¯å‰‡ä¿®æ­£)
            if not gpt_response.startswith("æˆ‘è¦‹åˆ°"):
                print("[DEBUG] å›æ‡‰ä¸ä»¥ã€Œæˆ‘è¦‹åˆ°ã€é–‹é ­ï¼Œæ·»åŠ å‰ç¶´")
                gpt_response = "æˆ‘è¦‹åˆ°" + gpt_response

            # ä½¿ç”¨ç¾æœ‰çš„ generate_tts å‡½æ•¸
            print(f"[DEBUG] ç”ŸæˆTTSï¼Œä½¿ç”¨æ–‡æœ¬: {gpt_response}")
            tts_file = generate_tts(gpt_response)

            if tts_file:
                print(f"[DEBUG] TTSç”ŸæˆæˆåŠŸ: {tts_file}")

                # è¨˜éŒ„AIå›æ‡‰åˆ°èŠå¤©æ­·å²
                ai_message = {
                    "type": "received",
                    "text": gpt_response,
                    "timestamp": datetime.now().isoformat(),
                    "audioSrc": tts_file
                }
                save_chat_message(ai_message)

                # å¦‚æœæª¢æ¸¬åˆ°äººç‰©ï¼Œå˜—è©¦åŸ·è¡Œæ®æ‰‹å‹•ä½œ (ä½¿ç”¨å…¨å±€å‡½æ•¸)
                if detected_person:
                    print("[DEBUG] æª¢æ¸¬åˆ°äººç‰©ï¼ŒåŸ·è¡Œæ®æ‰‹å‹•ä½œ")
                    try:
                        # ç›´æ¥èª¿ç”¨ï¼Œä¸ç”¨ä»»ä½•å°å…¥
                        result = subprocess.run([
                            "curl",
                            "-X", "POST", "http://192.168.149.1:9030/",
                            "-H", "deviceid: your_device_id",
                            "-H", "X-JSON-RPC: RunAction",
                            "-H", "er: false",
                            "-H", "dr: false",
                            "-H", "Content-Type: text/x-markdown; charset=utf-8",
                            "-H", "Content-Length: 76",
                            "-H", "Connection: Keep-Alive",
                            "-H", "Accept-Encoding: gzip",
                            "-H", "User-Agent: okhttp/4.9.1",
                            "-d", '{"id":1732853986186,"jsonrpc":"2.0","method":"RunAction","params":["9","1"]}'
                        ], capture_output=True, text=True)

                        print(f"[DEBUG] æ®æ‰‹å‹•ä½œåŸ·è¡Œçµæœ: {result.stdout}")

                        # æ·»åŠ æ©Ÿå™¨äººå‹•ä½œè¨Šæ¯åˆ°èŠå¤©è¨˜éŒ„
                        action_message = {
                            "type": "received",
                            "text": "ğŸ¤– åŸ·è¡Œå‹•ä½œ: æ®æ‰‹ å·²å®Œæˆ",
                            "timestamp": datetime.now().isoformat(),
                            "audioSrc": None
                        }
                        save_chat_message(action_message)

                    except Exception as action_error:
                        print(f"[ERROR] åŸ·è¡Œå‹•ä½œå¤±æ•—: {action_error}")

                # è¿”å›æˆåŠŸçµæœ
                return jsonify({
                    'success': True,
                    'image_url': f"/static/uploads/test/{filename}",
                    'caption': caption,
                    'tags': tags,
                    'objects': objects,
                    'analysis_text': gpt_response,
                    'tts_file': tts_file,
                    'detected_person': detected_person
                })
            else:
                # TTSç”Ÿæˆå¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨æ–¹æ¡ˆ
                print("[WARNING] TTSç”Ÿæˆå¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨æ–¹æ¡ˆ")
                raise Exception("TTSç”Ÿæˆå¤±æ•—")

        except Exception as e:
            # è©³ç´°è¨˜éŒ„éŒ¯èª¤
            print(f"[ERROR] GPTè™•ç†å¤±æ•—: {str(e)}")
            import traceback
            traceback.print_exc()

            # å‰µå»ºæ›´è‡ªç„¶çš„å»£æ±è©±å‚™ç”¨å›æ‡‰
            backup_response = f"æˆ‘è¦‹åˆ°åœ–ç‰‡ä¸­æœ‰{caption}"

            if objects and len(objects) > 0:
                # åªä½¿ç”¨å‰3å€‹ç‰©é«”ï¼Œé¿å…éé•·
                shown_objects = objects[:3]
                backup_response = f"æˆ‘è¦‹åˆ°åœ–ç‰‡ä¸­æœ‰{', '.join(shown_objects)}"

            print(f"[DEBUG] ä½¿ç”¨å‚™ç”¨å›æ‡‰: {backup_response}")

            # ç”Ÿæˆå‚™ç”¨TTS
            backup_tts_file = generate_tts(backup_response)

            # è¨˜éŒ„åŸºæœ¬å›æ‡‰åˆ°èŠå¤©æ­·å²
            basic_message = {
                "type": "received",
                "text": backup_response,
                "timestamp": datetime.now().isoformat(),
                "audioSrc": backup_tts_file
            }
            save_chat_message(basic_message)

            # å¦‚æœæª¢æ¸¬åˆ°äººç‰©ï¼ŒåŸ·è¡Œæ®æ‰‹å‹•ä½œ
            if detected_person:
                try:
                    # ç›´æ¥åŸ·è¡Œå‘½ä»¤ï¼Œä¸ä¾è³´å¤–éƒ¨å‡½æ•¸
                    result = subprocess.run([
                        "curl",
                        "-X", "POST", "http://192.168.149.1:9030/",
                        "-H", "deviceid: your_device_id",
                        "-H", "X-JSON-RPC: RunAction",
                        "-H", "er: false",
                        "-H", "dr: false",
                        "-H", "Content-Type: text/x-markdown; charset=utf-8",
                        "-H", "Content-Length: 76",
                        "-H", "Connection: Keep-Alive",
                        "-H", "Accept-Encoding: gzip",
                        "-H", "User-Agent: okhttp/4.9.1",
                        "-d", '{"id":1732853986186,"jsonrpc":"2.0","method":"RunAction","params":["9","1"]}'
                    ], capture_output=True, text=True)

                    # æ·»åŠ æ©Ÿå™¨äººå‹•ä½œè¨Šæ¯åˆ°èŠå¤©è¨˜éŒ„
                    action_message = {
                        "type": "received",
                        "text": "ğŸ¤– åŸ·è¡Œå‹•ä½œ: æ®æ‰‹ å·²å®Œæˆ",
                        "timestamp": datetime.now().isoformat(),
                        "audioSrc": None
                    }
                    save_chat_message(action_message)

                except Exception as action_error:
                    print(f"[ERROR] åŸ·è¡Œå‹•ä½œå¤±æ•—: {action_error}")

            # è¿”å›å‚™ç”¨å›æ‡‰
            return jsonify({
                'success': True,
                'image_url': f"/static/uploads/test/{filename}",
                'caption': caption,
                'tags': tags,
                'objects': objects,
                'analysis_text': backup_response,
                'tts_file': backup_tts_file,
                'detected_person': detected_person
            })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'message': f'è™•ç†åœ–ç‰‡æ™‚å‡ºéŒ¯: {str(e)}'
        }), 500

# æ·»åŠ æ¸¬è©¦éŸ³é »ä¸Šå‚³å’Œè™•ç†çš„è·¯ç”±


@app.route('/api/test/upload-audio', methods=['POST'])
def test_upload_audio():
    try:
        # æª¢æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶è¢«ä¸Šå‚³
        if 'audio' not in request.files:
            return jsonify({
                'success': False,
                'message': 'æœªæ‰¾åˆ°éŸ³é »æ–‡ä»¶'
            }), 400

        audio_file = request.files['audio']

        # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰å…§å®¹
        if audio_file.filename == '':
            return jsonify({
                'success': False,
                'message': 'æœªé¸æ“‡æ–‡ä»¶'
            }), 400

        # æª¢æŸ¥æ–‡ä»¶é¡å‹
        if not audio_file.filename.lower().endswith('.wav'):
            return jsonify({
                'success': False,
                'message': 'åªæ”¯æŒWAVæ ¼å¼çš„éŸ³é »æ–‡ä»¶'
            }), 400

        # ç¢ºä¿ä¸Šå‚³ç›®éŒ„å­˜åœ¨
        upload_dir = os.path.join('static', 'uploads', 'test')
        os.makedirs(upload_dir, exist_ok=True)

        # ä¿å­˜æ–‡ä»¶
        filename = f"test_audio_{int(time.time())}.wav"
        filepath = os.path.join(upload_dir, filename)
        audio_file.save(filepath)

        # è½‰éŒ„éŸ³é »
        transcribed_text = transcribe_audio(filepath)

        # ç²å–AIå›æ‡‰
        ai_response = None
        response_audio_url = None

        if transcribed_text:
            # ä½¿ç”¨chatbotè™•ç†æ–‡æœ¬
            ai_response = chatbot.get_response(transcribed_text)

            # ç”ŸæˆTTS
            if ai_response:
                tts_file = generate_tts(ai_response)
                if tts_file:
                    response_audio_url = tts_file

        # è¿”å›çµæœ
        return jsonify({
            'success': True,
            'text': transcribed_text,
            'response': ai_response,
            'audio_url': f"/static/uploads/test/{filename}",
            'response_audio': response_audio_url
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'message': f'è™•ç†éŸ³é »æ™‚å‡ºéŒ¯: {str(e)}'
        }), 500


@app.route('/api/settings/whisper', methods=['POST'])
def update_whisper_settings():
    try:
        data = request.json
        mode = data.get('mode')
        config = {
            'local_whisper_model': data.get('local_model'),
            'azure_whisper_model': data.get('azure_model')
        }

        # ä½¿ç”¨é¸æ“‡å™¨åˆ‡æ›æ¨¡å¼
        result = stt_selector.switch_mode(mode, config)

        # ç²å–ç•¶å‰ç‹€æ…‹
        status = stt_selector.get_status()

        return jsonify({
            'success': True,
            'message': result,
            'current_status': status
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        }), 400

# æ·»åŠ ç²å–ç•¶å‰Whisperè¨­ç½®çš„API


@app.route('/api/settings/whisper', methods=['GET'])
def get_whisper_settings():
    try:
        status = stt_selector.get_status()
        return jsonify({
            'success': True,
            'current_status': status
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        }), 500


@app.route('/api/test/whisper-status', methods=['GET'])
def test_whisper_status():
    """æ¸¬è©¦Whisperç‹€æ…‹ï¼Œè¿”å›è©³ç´°è³‡è¨Š"""
    try:
        status = stt_selector.get_status()

        # æ¸¬è©¦Azureèªè­‰
        azure_creds_ok = False
        azure_error = None
        try:
            api_key = os.getenv("AZURE_OPENAI_API_KEY")
            endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
            azure_creds_ok = api_key is not None and endpoint is not None
        except Exception as e:
            azure_error = str(e)

        # å˜—è©¦åˆå§‹åŒ–Azureå®¢æˆ¶ç«¯
        azure_init_ok = False
        azure_init_error = None
        if status['mode'] == 'azure':
            try:
                stt_selector._initialize_azure_client()
                azure_init_ok = True
            except Exception as e:
                azure_init_error = str(e)

        return jsonify({
            'success': True,
            'current_status': status,
            'azure_credentials_ok': azure_creds_ok,
            'azure_init_ok': azure_init_ok,
            'azure_error': azure_error,
            'azure_init_error': azure_init_error,
            'config': {
                'AZURE_SPEECH_API_KEY': os.getenv("AZURE_SPEECH_API_KEY", "æœªè¨­ç½®")[:4] + "..." if os.getenv("AZURE_SPEECH_API_KEY") else "æœªè¨­ç½®",
                'AZURE_SPEECH_REGION': os.getenv("AZURE_SPEECH_REGION", "æœªè¨­ç½®"),
                'WHISPER_CONFIG': WHISPER_CONFIG,
            }
        })
    except Exception as e:
        traceback.print_exc()
        return jsonify({
            'success': False,
            'message': str(e)
        }), 500

# è™•ç†å–®ä½æ•¸å‹•ä½œ


@app.route('/execute_singledigit_action', methods=['POST'])
def execute_singledigit_action_route():
    try:
        data = request.json
        if 'params' not in data:
            return jsonify({"error": "Missing 'params' field"}), 400

        params = data['params']

        # è¨˜éŒ„æ”¶åˆ°çš„åƒæ•¸
        logging.info(f"æ”¶åˆ°å–®ä½æ•¸å‹•ä½œåƒæ•¸: {params}")

        # å˜—è©¦ç²å–ä¸¦è™•ç†åƒæ•¸
        try:
            if isinstance(params, list) and len(params) >= 2:
                action_id = params[0]
                repeat_count = params[1]
            elif isinstance(params, str):
                # å…¼å®¹èˆŠæ ¼å¼
                import json
                try:
                    params_array = json.loads(params)
                    action_id = params_array[0]
                    repeat_count = params_array[1]
                except:
                    # ç„¡æ³•è§£æï¼Œä½¿ç”¨åŸå§‹æ•¸æ“š
                    return execute_singledigit_action(params, "1")
            else:
                # åƒæ•¸æ ¼å¼ä¸æ˜¯é æœŸçš„
                return jsonify({"error": f"Unexpected params format: {type(params)}"}), 400

            return execute_singledigit_action(action_id, repeat_count)
        except Exception as e:
            logging.error(f"è™•ç†å–®ä½æ•¸å‹•ä½œåƒæ•¸å¤±æ•—: {e}")
            # å˜—è©¦ç›´æ¥ä½¿ç”¨åŸå§‹åƒæ•¸
            return execute_singledigit_action(params, "1")

    except Exception as e:
        logging.error(f"åŸ·è¡Œå–®ä½æ•¸å‹•ä½œè·¯ç”±è™•ç†å¤±æ•—: {e}")
        return jsonify({"error": str(e)}), 500


@app.route('/execute_doubledigit_action', methods=['POST'])
def execute_doubledigit_action_route():
    try:
        data = request.json
        if 'params' not in data:
            return jsonify({"error": "Missing 'params' field"}), 400

        params = data['params']

        # è¨˜éŒ„æ”¶åˆ°çš„åƒæ•¸
        logging.info(f"æ”¶åˆ°é›™ä½æ•¸å‹•ä½œåƒæ•¸: {params}")

        # å˜—è©¦ç²å–ä¸¦è™•ç†åƒæ•¸
        try:
            if isinstance(params, list) and len(params) >= 2:
                action_id = params[0]
                repeat_count = params[1]
            elif isinstance(params, str):
                # å…¼å®¹èˆŠæ ¼å¼
                import json
                try:
                    params_array = json.loads(params)
                    action_id = params_array[0]
                    repeat_count = params_array[1]
                except:
                    # ç„¡æ³•è§£æï¼Œä½¿ç”¨åŸå§‹æ•¸æ“š
                    return execute_doubledigit_action(params, "1")
            else:
                # åƒæ•¸æ ¼å¼ä¸æ˜¯é æœŸçš„
                return jsonify({"error": f"Unexpected params format: {type(params)}"}), 400

            return execute_doubledigit_action(action_id, repeat_count)
        except Exception as e:
            logging.error(f"è™•ç†é›™ä½æ•¸å‹•ä½œåƒæ•¸å¤±æ•—: {e}")
            # å˜—è©¦ç›´æ¥ä½¿ç”¨åŸå§‹åƒæ•¸
            return execute_doubledigit_action(params, "1")

    except Exception as e:
        logging.error(f"åŸ·è¡Œé›™ä½æ•¸å‹•ä½œè·¯ç”±è™•ç†å¤±æ•—: {e}")
        return jsonify({"error": str(e)}), 500


def record_audio(output_file="recorded_audio.wav"):
    """ä½¿ç”¨ sounddevice éŒ„éŸ³"""
    print("[INFO] é–‹å§‹éŒ„éŸ³...")
    audio_data = sd.rec(int(SAMPLE_RATE * DURATION),
                        samplerate=SAMPLE_RATE, channels=CHANNELS, dtype=np.int16)
    sd.wait()  # ç­‰å¾…éŒ„éŸ³å®Œæˆ
    wav.write(output_file, SAMPLE_RATE, audio_data)  # å„²å­˜éŸ³æª”
    print(f"[INFO] éŒ„éŸ³å®Œæˆï¼Œå„²å­˜è‡³ {output_file}")

    return output_file


def send_audio_to_robot(audio_file):
    """å°‡éŸ³é »æ–‡ä»¶ç™¼é€åˆ°æ©Ÿå™¨äººç«¯æ’­æ”¾"""
    try:
        # è®€å–éŸ³é »æ–‡ä»¶æ•¸æ“š
        with open(audio_file, 'rb') as f:
            audio_data = f.read()

        # å‘æ‰€æœ‰é€£æ¥çš„æ©Ÿå™¨äººç™¼é€éŸ³é »æ•¸æ“š
        for robot_id in connected_robots:
            socketio.emit('play_audio', {
                'audio_data': audio_data
            }, room=robot_id)
            logging.info(f"ç™¼é€éŸ³é »åˆ°æ©Ÿå™¨äºº {robot_id}")
    except Exception as e:
        logging.error(f"ç™¼é€éŸ³é »åˆ°æ©Ÿå™¨äººå¤±æ•—: {e}")


def main():
    # åˆå§‹åŒ– PhoneMode å¯¦ä¾‹
    global phone_mode_manager
    phone_mode_manager = PhoneMode(
        socketio=socketio,
        chatbot=chatbot,
        transcribe_func=transcribe_audio,
        tts_func=generate_tts,
        save_message_func=save_chat_message,
        should_trigger_vision_func=should_trigger_vision,
        analyze_frame_func=analyze_current_frame
    )

    # åˆå§‹åŒ–èŠå¤©æ­·å²
    initialize_chat_history()

    # æ³¨å†Œæ‰€æœ‰å¥—æ¥å­—å¤„ç†ç¨‹åº
    register_socket_handlers(
        socketio, stt_selector, chatbot, current_input_mode,
        current_output_mode, phone_mode_manager, phone_mode_active,
        should_trigger_vision, analyze_current_frame, save_chat_message,
        generate_tts, record_audio, pc_recorder, connected_robots
    )

    try:
        # å¼·åˆ¶è¨­ç½®ç‚º Azure æ¨¡å¼
        logging.info("å˜—è©¦å¼·åˆ¶è¨­ç½® Whisper ç‚º Azure æ¨¡å¼...")
        stt_selector.switch_mode("azure")
        status = stt_selector.get_status()
        logging.info(f"Whisper ç•¶å‰ç‹€æ…‹: {status}")

        # åˆå§‹åŒ– Azure å®¢æˆ¶ç«¯
        logging.info("å¼·åˆ¶åˆå§‹åŒ– Azure å®¢æˆ¶ç«¯...")
        stt_selector._initialize_azure_client()
        logging.info("Azure å®¢æˆ¶ç«¯åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        logging.error(f"å¼·åˆ¶è¨­ç½® Azure æ¨¡å¼å¤±æ•—: {e}")
        traceback.print_exc()


if __name__ == '__main__':
    main()
    logging.info("PC æœåŠ¡ç«¯å¯åŠ¨äº 0.0.0.0:5001")
    socketio.run(app, host='0.0.0.0', port=5001, debug=True)
